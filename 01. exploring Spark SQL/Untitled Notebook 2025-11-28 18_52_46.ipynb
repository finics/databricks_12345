{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b047e75d-9091-44d6-aa6f-b2045d68d0ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(\n",
    "    path=\"/Volumes/quickstart_catalog/quickstart_schema/sandbox/dataset/employee.csv\",\n",
    "    header=True,\n",
    "    inferSchema=True,\n",
    "    sep=\"|\",\n",
    "    #timestampFormat=\"yyyy-MM-dd'T'HH:mm:ss.SSSXXX\n",
    ")\n",
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5d028c0-9610-479d-b289-18ee7edb74bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import array_contains,split\n",
    "filtered_df = df.filter(\n",
    "    array_contains(\n",
    "        df.skills,  # Split string into array\n",
    "        \"PySpark\"\n",
    "    )\n",
    ")\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bfe7a19d-6bc5-40dd-b753-eed8bd068ee7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "df_split = df.withColumn(\"current_salary\", split(df.col_current_expected_salary, \",\")[0]) \\\n",
    "             .withColumn(\"expected_salary\", split(df.col_current_expected_salary, \",\")[1])\n",
    "\n",
    "display(df_split)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Untitled Notebook 2025-11-28 18_52_46",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
